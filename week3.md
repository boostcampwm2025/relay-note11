# **“부스트캠프 커뮤니티 또는 개발자로서 학습과 성장을 위해 AI 활용하기”**

## 🗣️ 토론 과정

### 🤖 각자의 AI 경험 공유

주로 지식 습득이나 학습에 활용하였다.

→ 하지만 AI 활용이 학습의 본질을 흐리게 해선 안 되고, 주객전도가 되면 안 된다.

특정 주제나 컨셉에 따라 프롬프트가 잘 작동하지 않는 경우가 있다.

자신의 이해 수준을 점검하거나 사고의 방향을 잡는 메타인지 도구로 활용한다.

### 🛠️ 개선 사항

각 퀘스트를 개선하거나 새롭게 변경한다.

- **퀘스트 1: 개념 비유로 정복하기**

  개념을 비유뿐만 아니라 예시와 같이 개념을 학습한다.

  미션 키워드 중에서 한 번 접해본 개념은 예시, 아예 처음이면 비유를 통해 학습한다.

  다양한 방식으로 접근하여, 공부 효과를 높이고자 한다.

- **퀘스트 2: AI와 함께하는 미션 뒷담화**

  이전 퀘스트에서는 공감 위주 퀘스트였는데, 이를 해결 위주(코드 구현 X, 방향성 제시)의 퀘스트로 변경하고자 한다.

  공감뿐 아니라 학습에도 보다 효율적으로 도움이 될 수 있도록 개선한다.

- **퀘스트 3: 완전 럭키비키잖아~? → 주제 변경: 프롬프트 템플릿**

  퀘스트 주제를 학습에 포커싱 하여 개념 학습을 위한 프롬프트 템플릿 작성 및 실천 퀘스트로 변경한다.

- **퀘스트 4: 할 말 다하기 프로젝트 → 주제 변경: AI와 학습 플래너 만들기**

  주제를 학습할 키워드에 대해 각 시간이 얼마나 소요되는지 하루 학습 플래너를 요청하는 것으로 변경한다.

## 🔍 조사하기

### 📚 1번 퀘스트 조사하기

- Mayer (2024), “The Past, Present, and Future of the Cognitive Theory of Multimedia Learning,” Educational Psychology Review

  40 여 년간 1000 건이 넘는 실험을 종합해, ‘단어+그림(또는 애니메이션)’이 ‘단어만’ 제시할 때보다 학습자의 이해·전이 점수를 유의미하게 끌어올리는 멀티미디어 원리를 비롯해 15개의 증거 기반 설계 원칙 제시하고 있습니다.

  https://link.springer.com/article/10.1007/s10648-023-09842-1

- 에빙하우스의 망각곡선

  https://ko.wikipedia.org/wiki/%EB%A7%9D%EA%B0%81_%EA%B3%A1%EC%84%A0

- Cepeda et al. (2006), “Distributed Practice in Verbal Recall Tasks: A Review and Quantitative Synthesis,” Psychological Bulletin

  184편 논문 317개 실험(효과크기 839개)을 통합-분석. 동일 학습 시간일 때 분산 학습이 밀집 학습보다 평균 d ≈ 0.46, 장기-전이 점수를 약 15 % 이상 끌어올립니다.

  https://pubmed.ncbi.nlm.nih.gov/16719566/

### 📘 2번 퀘스트 조사하기

이미 챗봇이나 어시스턴트 등의 AI 기반 해결 도구(GitHub Copilot Chat)이나 JetBrains AI Assistant 등이 많이 있고 능력이 증명된 상태기에 충분히 실현 가능하고 사용자의 학습 경험에 긍정적인 효과를 줄 것으로 기대됩니다.

### 📙 3번 퀘스트 조사하기

프롬프트 엔지니어링에 대한 학술적 연구는 주로 대규모 언어 모델(LLM)의 성능을 향상시키기 위한 다양한 기법들을 체계적으로 분류하고 실험하는 방식으로 진행되고 있습니다. 다음은 참고할 만한 논문 유형입니다.

- **체계적 조사(Systematic Survey)**

  'A Systematic Survey of Prompt Engineering in Large Language Models'와 같은 논문들은 프롬프트 엔지니어링의 다양한 기술들을 분류하고, 각 기술의 장점과 한계를 분석합니다. 복잡한 기법들의 전체적인 그림을 파악하는 데 도움이 됩니다.

- **특정 기법 연구**

  'Chain-of-Thought Prompting'이나 'Tree of Thoughts'와 같이, AI가 복잡한 문제를 해결하는 과정을 여러 단계로 나누어 생각하도록 유도하는 특정 프롬프트 기법을 심도 있게 다루는 논문들도 있습니다. 이는 고급 프롬프트 기술의 원리를 이해하는 데 유용합니다.

### 📕 4번 퀘스트 조사하기

4번 퀘스트에 대해 AI에게 학습 플래너를 요청하였습니다.

미션 `Day13 버전 관리 도구 `에서 학습할 키워드 로 학습 플래너를 요청하였고, 그 결과 학습 플래너를 받을 수 있었습니다.

**AI 답변 결과**

| 시간(분) | 키워드          | 학습 목표                                  |
| -------- | --------------- | ------------------------------------------ |
| 30분     | VCS 개념        | 버전 관리의 목적과 분산형 시스템 개념 이해 |
| 30분     | Git             | Git의 구조, add/commit/stage의 역할 이해   |
| 20분     | GitHub          | 리모트 저장소와 GitHub의 기능 파악         |
| 20분     | Repository/File | 저장소 구조와 파일 상태 전이 학습          |
| 20분     | SHA             | 커밋 해시로 버전 추적하는 방식 이해        |
| 30분     | 문서화          | 각 키워드에 대해 요약 정리 (마크다운 등)   |
| 30분     | 실습            | 실제 Git 명령어 실습 및 기록 남기기        |
| 30분     | 피드백 정리     | 실습 중 느낀 점, 어려웠던 부분 회고 작성   |

## 🎯 퀘스트 제작

### 🧠 퀘스트 1: 개념 패러라이징하기

- **퀘스트 배경**: 개념을 어떻게 하면 깊게, 오래 기억할 수 있는 방법에 대해 고민해보았습니다.

- **퀘스트 목표**: CS 개념을 다양한 방식으로 학습하여, 학습효과를 높이고, 장기기억으로 옮기고자 합니다.

- **수행 방법**:

  1. 여태까지 수행했던 미션의 키워드 중 1개를 선정합니다.
  2. 해당 개념에 대해 비유나 예시 중 하나를 택합니다. 그 외에 원하시는 방식도 좋습니다!
     - 아직 해당 개념이 익숙하지 않다면 비유를, 조금 더 자세히 공부하고 싶다면 예시를 추천드립니다!
  3. 해당 개념을 정한 방식에 따라 AI 에게 요청합니다.
  4. AI 의 결과를 이해하고, 분석하여 비슷하게 본인만의 말로 표현해봅니다.

- **기대 효과**:

  오감을 통한 학습이 효과적이듯이, 다양한 방식으로 개념을 공부함으로서 해당 개념을 더욱 깊게 이해되는 것을 기대합니다.

  또한, 이미 학습한 내용을 복습함으로서 장기기억으로 오래 유지되길 기대합니다.    

### 😈 퀘스트 2: AI와 함께하는 미션 뒷담화

- **퀘스트 배경**: 미션 진행 중 막히는 부분에서 오는 스트레스는 지속 가능한 학습을 방해하고, 학습 자체를 부정적으로 느끼게 만든다.

- **개선 퀘스트 목표** : 이전 퀘스트에서는 공감 위주 퀘스트였는데, 이를 해결 위주(직접적 구현 x)의 퀘스트로 변경하고자 한다.

  - '뒷담을 나누는 대상' 에서 '해결사'로

    - 미션을 진행 중 막히는 부분에서 오는 스트레스를 푸는 감정적 해소 뿐만 아니라, 막힌 상황을 돌파할 생각의 전환이나 새로운 관점을 제시한다. (핵심은 힌트만 주고 구현 등의 직접적 해답을 주지 않는 것)

    - 미션 중 막히는 부분에 대한 불평과 뒷담을 늘어놓는건 똑같지만, 이 '막히는 부분'에 대한 힌트를 제공한다. 감정적 위로를 받을 수 있을 뿐만 아니라 각 '장애물' 에 대한 맞춤 힌트가 제공되기에 마지막에 대화를 정리할 때 보다 쉽게 문제점을 찾을 수 있을 것이다.

- **수행 방법**: 한 주에 진행하는 미션에 AI 해결사를 적용시켜본다. 막힌 부분을 토로하고, 미션을 끝냈을 때 트러블 슈팅처럼 '벽에 막힌' 기록이 **하나라도** 대화에 있다면 성공 (다수일 필요 x)

### ✍️ 퀘스트 3: 프롬프트 얼마나 잘 써봤니?

- **퀘스트 배경**: 프롬프트를 어떻게 작성하느냐에 따라 답변의 퀄리티와 의도는 천차만별이다. 이를 통제하고 규격화하기 위해 프롬프트 작성 요령을 실습해본다.

- **퀘스트 목표**: 템플릿을 통한 쿼리와, 일반적으로 원래 사용하던 쿼리의 결과를 비교하여, 무엇이 학습에 더 효과적인지 확인한다. 앞으로 이 프롬프트 템플릿을 어떻게 활용할 수 있는지 정리해본다.

- **수행 방법**: 아래의 수행방법을 따라 보고서를 작성한다.

- **기대 효과** : 앞으로 프롬프트 작성을 잘 할 수 있는 템플릿들을 만들어, 필요상황에 맞는 ai활용을 기대할 수 있다.

**템플릿 예시**

```
# 프롬프트 템플릿

### 1. 역할 (Persona)
너는 지금부터 [ OOO 전문가 ] 야.

### 2. 지시사항 (Instruction)
내가 제공하는 [ 자료 ]를 바탕으로 [ 목표 ]를 위해 다음 작업을 수행해 줘.

### 3. 맥락 (Context)
- 작업의 배경: [ 왜 이 작업이 필요한지 설명 ]
- 대상: [ 이 결과물을 누가 보거나 사용하는지 설명 (예:개발자, 비전공자, 팀장님) ]
- 핵심 목표: [ 가장 중요하게 생각하는 결과물의 특징 (예: 가독성, 전문성, 창의성) ]

### 4. 출력 형식 (Format)
- 전체 구조: [ 예: 서론-본론-결론 구조, 마크다운 형식, 테이블 형식 ]
- 스타일 및 톤: [ 예: 친근한 말투, 전문가적인 톤, 유머러스하게 ]
- 언어: [ 예: 한국어, 영어 (기술 용어는 영어 유지) ]

### 5. 제약 조건 (Constraints)
- [ 반드시 포함할 내용 또는 키워드 ]
- [ 절대로 포함하지 말아야 할 내용 ]
- [ 분량 제한 (예: 500자 이내, 3문단으로 요약) ]
```

- 수행방법

  1. 프롬프트 템플릿 적용해보기. (예시)

  ```
  너는 지금부터 [ 함수형 프로그래밍 전문가 ] 야.

  내가 제공하는 [ 자료없음 ]를 바탕으로 [내 cs 지식 습득을 위해] 다음 작업을 수행해 줘.

  - 작업내용 : [함수형 프로그래밍을 잘 짜는 법 꿀팁을 알려줘]

  - 작업의 배경: [전문적 지식 획득]
  - 대상: [ 초보개발자 ]
  - 핵심 목표: [ 전문성, 가독성 ]

  - 전체 구조: [ 마크다운 형식 ]
  - 스타일 및 톤: [ 전문가 ]

  - [ 분량 제한 없음 ]
  ```

  2. 위 템플릿으로 적용한 ai의 답변 쓰기

     > 여기에 답변 쓰기

  3. '함수형 프로그래밍을 잘 짜는 법 꿀팁을 알려줘 'ai의 답변

     > 여기에 답변 쓰기

  4. 어떤 차이점이 있는지 확인하기
     여기에 차이점을 3가지 이상 쓰기.

  5. 앞으로 ai를 다룰 때 어떻게 활용하면 좋을지 생각을 써보기
     > 여기에 생각 쓰기

### ⏱️ 퀘스트 4: AI와 학습 플래너 만들기

- **퀘스트 배경**: 구현하기 전 학습을 진행할 때, 학습에 얼마나 시간을 투자해야 할지 명확하지 않아 학습이 예상보다 길어지고, 일정이 지연되는 문제가 발생한 적이 있습니다.

- **퀘스트 목표**: AI가 제안한 학습 시간 분배 플래너로 학습을 계획적으로 진행하여 시간 관리 능력을 향상시키는 것이 목표입니다.

- **수행 방법**:

  - 학습할 키워드를 미리 정리합니다.
  - 학습할 키워드에 대해 AI에게 하루 기준 시간 분배가 포함된 학습 플래너를 요청합니다.
  - AI가 제안한 학습 플래너에 따라 학습을 진행합니다.

- **기대 효과**: 효율적인 일정 관리

------

## 수행 결과

### J283 한지은
- 선택한 퀘스트: 퀘스트 4 AI와 학습 플래너 만들기
- 선택한 이유: 짝 프로그래밍을 진행하면서 학습할 키워드를 같이 정하고, 설계하기 전 정해진 시간까지 각자 학습한 후 모이기로 하였습니다. 당시 학습 시간이 정해져있다보니 핵심만 빠르게 파악한 후 필요한 부분은 깊게 들어갈 수 있어 좋은 경험이라고 느꼈습니다. 따라서 4번 퀘스트를 통해 AI를 짝처럼 플래너를 같이 결정하면 시간 관리에 효율적일 것 같아 선택하였습니다.
- 
### J181 이도현
- 선택한 퀘스트: 퀘스트 3 프롬프트 얼마나 잘 써봤니?
- 선택한 이유: 항상 AI에게 질 높은 답변을 어떻게하면 이끌어낼 수 있을까에 대한 고민이 있었습니다. 다양한 프롬프트를 써보며 어떤 프롬프트가 AI에게 질 좋은 질문을 뱉어내게 하는데에 효과적인지 알아보고 싶었습니다.

- 수행 방법
  1. 프롬프트 템플릿 적용해보기.

```
# 프롬프트 템플릿
1. 역할 (Persona)
너는 지금부터 [ 벡터 DB 개념 전문가 ] 야. 

2. 지시사항 (Instruction)
내가 제공하는 [ 자료 ]를 바탕으로 [ 목표 ]를 위해 다음 작업을 수행해 줘.

자료는 없고, 목표는 word2vec에 대한 설명이야.



3. 맥락 (Context)
- 작업의 배경: 벡터 DB에서의 딥러닝 기반의 사전 학습 모델을 이해하기 위해 필요해
- 대상: 개발자 
- 핵심 목표: 가독성 
4. 출력 형식 (Format)
- 전체 구조: 마크다운 형식
- 스타일 및 톤: 전문가적인 톤 
- 언어: [ 예: 한국어, 영어 (기술 용어는 영어 유지) ]

5. 제약 조건 (Constraints)
- 임베딩 과정에서 딥러닝 기반의 사전 학습 모델이 왜 필요한지를 먼저 설명하고, 개념을 설명해줘. 
- [ 분량 제한 (예: 10000자 이내)]
  ```

  2. 위 템플릿으로 적용한 ai의 답변 쓰기
```
# Word2Vec: 딥러닝 기반 임베딩 모델의 핵심 이해

## 🧠 왜 딥러닝 기반 사전 학습 모델이 필요한가?

벡터 DB는 텍스트, 이미지, 음성 같은 비정형 데이터를 숫자 벡터로 변환하여 저장하고 유사도 기반 검색을 가능하게 합니다. 이 변환 과정을 **임베딩(embedding)**이라고 하며, 이 임베딩의 품질이 검색 정확도를 좌우합니다.

전통적인 방법(예: Bag of Words, TF-IDF)은 단어 간 의미 관계를 반영하지 못해 제한적이었습니다. 하지만 **딥러닝 기반의 사전 학습 모델**은 대량의 텍스트 데이터를 학습하여 단어 간 의미적, 문맥적 관계를 파악할 수 있는 벡터를 생성합니다. 이로 인해 의미 기반 검색, 추천 시스템, 질의 응답 시스템의 성능이 비약적으로 향상되었습니다.

대표적인 딥러닝 임베딩 모델 중 하나가 바로 **Word2Vec**입니다.

---

## 📌 Word2Vec이란?

**Word2Vec**은 2013년 Google에서 발표한 단어 임베딩 모델로, 단어를 고정된 크기의 실수 벡터로 변환합니다. 이 벡터는 단어 간의 **의미적 유사성**을 반영하며, 유사한 의미의 단어일수록 가까운 벡터로 표현됩니다.

예를 들어,  
- `king - man + woman ≈ queen`  
처럼 벡터 연산이 의미 있는 방식으로 동작합니다.

---

## ⚙️ Word2Vec의 학습 방식

Word2Vec은 다음 두 가지 방식 중 하나로 학습합니다:

### 1. CBOW (Continuous Bag of Words)
- **목표**: 주변 단어(context)들을 보고 중심 단어(target)를 예측
- **특징**: 자주 등장하는 단어 예측에 강함, 학습 속도 빠름
- **예시**:  
  “The **quick brown fox** jumps”  
  → "quick", "brown", "fox"를 보고 "jumps"를 예측

### 2. Skip-Gram
- **목표**: 중심 단어를 보고 주변 단어를 예측
- **특징**: 희귀 단어에 강함, 대용량 데이터에 효과적
- **예시**:  
  "jumps"를 보고 "quick", "brown", "fox"를 예측

---

## 🧮 수학적 개요

Word2Vec은 입력 단어를 one-hot 인코딩한 뒤, 이를 저차원 밀집 벡터(dense vector)로 변환합니다. 그 벡터는 은닉층(weight matrix)으로부터 학습되며, 이 과정은 지도 학습의 형태를 띄지만 레이블 대신 주변 단어를 예측하는 방식입니다.

- 입력층 → 은닉층(weight matrix) → 출력층(softmax)
- 학습 목표: 실제 주변 단어와 예측 결과 간의 오차를 최소화

---

## 📊 Word2Vec이 생성하는 임베딩의 특징

| 특징                     | 설명 |
|--------------------------|------|
| 의미 기반 유사성         | 유사한 의미의 단어는 가까운 벡터로 매핑됨 |
| 벡터 연산 가능           | 단어 간 관계를 벡터 산술로 표현 가능 |
| 고차원 공간에서의 효율성 | 벡터 DB의 검색 효율성과 직결 |

---

## 🧩 벡터 DB에서 Word2Vec의 역할

벡터 DB는 대규모 벡터를 저장하고, 입력 쿼리 벡터와 유사한 벡터를 빠르게 검색합니다. Word2Vec과 같은 임베딩 모델이 없다면 이러한 벡터 자체를 만들 수 없습니다. 즉, **임베딩 품질 = 검색 품질**입니다.

- 텍스트 → Word2Vec → 벡터 → 벡터 DB 저장
- 사용자 쿼리 → 동일 모델로 벡터화 → 유사도 검색 (예: cosine similarity)

---

## ✅ 정리

| 항목 | 내용 |
|------|------|
| 왜 필요한가? | 단어 간 의미 관계를 반영하는 고차원 벡터 생성 |
| 어떻게 작동하나? | 주변 단어 예측을 통해 은닉층 가중치를 임베딩으로 사용 |
| 벡터 DB와의 관계 | Word2Vec 임베딩은 벡터 DB에서 텍스트 유사도 검색의 핵심 |

Word2Vec은 벡터 DB의 기반이 되는 임베딩 품질을 결정하는 주요 도구입니다. 이를 이해함으로써, 개발자는 벡터 기반 검색 시스템의 성능을 근본적으로 개선할 수 있습니다.
```

  3. `딥러닝 기반 사전 학습 모델이 필요한가와  Word2Vec에 대한 설명을 마크다운으로 작성해줘` 에 대한 AI의 답변
```
물론입니다! 아래는 "왜 딥러닝 기반 사전 학습 모델이 필요한가"와 "Word2Vec에 대한 설명"을 마크다운 형식으로 정리한 내용입니다.

---

# 왜 딥러닝 기반 사전 학습 모델이 필요한가?

## 1. 언어의 복잡성과 다양성

* 자연어는 **동일한 단어라도 문맥에 따라 의미가 달라질 수 있음**.
* 예: "은행"은 금융 기관일 수도 있고, 강가일 수도 있음.
* 이런 **다의성**과 **문맥 의존성**을 다루기 위해서는 고도화된 모델이 필요함.

## 2. 규칙 기반 접근의 한계

* 과거에는 규칙 기반 혹은 통계 기반의 자연어 처리(NLP)가 주를 이룸.
* 그러나 이러한 접근법은 **유연성 부족**, **일반화 능력 부족** 등의 문제점이 있었음.

## 3. 데이터 활용 효율성

* 딥러닝 기반의 사전 학습 모델은 **대규모 말뭉치로부터 일반적인 언어 패턴을 학습**함.
* 학습된 모델을 다양한 downstream task (예: 분류, 질의응답, 요약 등)에 \*\*전이 학습(Fine-tuning)\*\*으로 활용 가능.
* → **전체적인 학습 비용 감소** 및 **성능 향상** 가능.

## 4. 문맥 기반 벡터 표현

* 기존의 단어 임베딩 방식은 문맥을 고려하지 않음(예: Word2Vec).
* 딥러닝 기반 사전 학습 모델(예: BERT, GPT)은 문맥을 동적으로 반영하여 **더 정밀한 의미 표현**이 가능함.

---

# Word2Vec란?

## 1. 개요

* Word2Vec은 **단어를 고정된 차원의 실수 벡터로 임베딩**하는 딥러닝 기반의 기법.
* 구글의 Tomas Mikolov 등이 2013년에 제안함.
* 비슷한 의미의 단어는 **비슷한 벡터값**을 갖도록 학습됨.

## 2. 학습 방식

Word2Vec은 다음 두 가지 방식 중 하나로 학습됨:

### ▸ CBOW (Continuous Bag of Words)

* 주변 단어(문맥)를 입력으로 주고, **중심 단어를 예측**.
* 예: “The cat sat on the *mat*” → “the”, “cat”, “on”, “the”로 “mat”을 예측

### ▸ Skip-Gram

* 중심 단어를 입력으로 주고, **주변 단어를 예측**.
* 예: “sat” → “cat”, “on”, “the”, “mat”을 예측

## 3. 주요 특징

* 학습 결과로 나온 벡터는 **의미적으로 유사한 단어가 가까운 벡터 공간에 위치**함.
* 벡터 연산도 가능함:

  * 예: `king - man + woman ≈ queen`
* 빠르고 간단하지만 **문맥 정보를 반영하지 못함**.

## 4. 한계

* 단어의 **고정 벡터**이기 때문에 **문맥에 따른 의미 변화 반영이 불가능**.
* 동일한 단어라도 **다른 문장에서 동일한 벡터를 가짐**.

---

### ✅ 요약

| 항목    | Word2Vec | 딥러닝 사전 학습 모델(BERT 등) |
| ----- | -------- | -------------------- |
| 문맥 반영 | ❌        | ✅                    |
| 연산 속도 | 빠름       | 느림                   |
| 전이 학습 | 제한적      | 매우 효과적               |
| 사용 목적 | 단어 간 유사도 | 문장 이해, 질의응답, 요약 등    |

---

필요하시면 BERT나 GPT처럼 Word2Vec 이후 등장한 대표적인 사전 학습 모델과의 비교도 정리해드릴 수 있어요.

```

  4. 어떤 차이점이 있는지 확인하기
     - 첫 번째 답변은 Word2Vec 자체에 대한 심층적인 원리 설명에 집중한 반면, 두 번째 답변은 Word2Vec을 더 넓은 딥러닝 임베딩 기술 발전 과정 속에서 설명한다.
     - 첫 번째 답변은 Word2Vec의 학습 방식을 설명하지만 문맥 반영의 한계를 명확히 지적하지 않는 반면, 두 번째 답변은 문맥 반영의 한계를 Word2Vec의 가장 중요한 특징으로 강조하고 다음 세대 모델과의 차이점을 제시한다.
     - 첫 번째 답변은 Word2Vec의 개요와 학습 방식, 수학적 개념을 상세히 설명하는 구조인 반면, 두 번째 답변은 "왜 필요한가?"라는 질문으로 시작해 Word2Vec의 한계를 언급하고 이후 모델들과 비교하는 논리적 흐름을 따릅니다.     

  6. 앞으로 ai를 다룰 때 어떻게 활용하면 좋을지 생각을 써보기
     > 프롬프트를 사용하면 특정 부분에 대해 깊이있게 알려주지만, 시대적 배경은 설명하지 않는 경우가 많았음. 따라서, 제약 조건에 추가적으로 알고 싶은 부분을 명시해줘야 함.

### J030 김동권
- 선택한 퀘스트: 퀘스트 4 AI와 학습 플래너 만들기
- 선택한 이유: 무작정 학습을 진행하게 되면 구현에 필요한 내용을 골고루 공부하기 어렵습니다. AI와 함께 학습 플래너를 만든다면 균형있는 계획을 세울 수 있을 것이라 기대하여 선택하게 되었습니다.


